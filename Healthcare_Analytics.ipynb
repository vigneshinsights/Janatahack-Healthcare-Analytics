{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set random seed\n",
    "random.seed(0)\n",
    "\n",
    "       \n",
    "    \n",
    "# Load data\n",
    "train = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Train.csv\", sep = \",\")\n",
    "test = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\test_l0Auv8Q.csv\", sep = \",\")\n",
    "camp_detail = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Health_Camp_Detail.csv', sep = \",\")\n",
    "patient_profile = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Patient_Profile.csv', sep = \",\")\n",
    "attended_health_camp_1 = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\First_Health_Camp_Attended.csv', sep = \",\")\n",
    "attended_health_camp_2 = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Second_Health_Camp_Attended.csv', sep = \",\")\n",
    "attended_health_camp_3 = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Third_Health_Camp_Attended.csv', sep = \",\")\n",
    "\n",
    "# Merge data\n",
    "train = train.merge(camp_detail, how = 'left', on = 'Health_Camp_ID')\n",
    "train = train.merge(patient_profile, how = 'left', on = 'Patient_ID')    \n",
    "\n",
    "test = test.merge(camp_detail, how = 'left', on = 'Health_Camp_ID') \n",
    "test = test.merge(patient_profile, how = 'left', on = 'Patient_ID')        \n",
    "\n",
    "# Add Outcome variable\n",
    "attended_health_camp_1 = attended_health_camp_1.drop(['Unnamed: 4'], axis = 1)\n",
    "attended_health_camp_1['Outcome'] = 1\n",
    "attended_health_camp_2['Outcome'] = 1       \n",
    "attended_health_camp_3['Outcome'] = [1 if x != 0 else 0 for x in attended_health_camp_3['Last_Stall_Visited_Number']] \n",
    "\n",
    "\n",
    "\n",
    "# Reduce dimensions\n",
    "columns = ['Health_Camp_ID', 'Patient_ID', 'Outcome']\n",
    "attended_health_camp_1 = attended_health_camp_1[['Patient_ID', 'Health_Camp_ID', 'Donation', 'Health_Score', 'Outcome']]\n",
    "attended_health_camp_2 = attended_health_camp_2[['Patient_ID', 'Health_Camp_ID', 'Health Score', 'Outcome']]\n",
    "attended_health_camp_3 = attended_health_camp_3[['Patient_ID', 'Health_Camp_ID', 'Number_of_stall_visited',\n",
    "       'Last_Stall_Visited_Number', 'Outcome']]\n",
    "\n",
    "# Concatenate data\n",
    "attended_all = pd.concat([attended_health_camp_1, attended_health_camp_2, attended_health_camp_3], axis = 0)\n",
    "\n",
    "train = train.merge(attended_all, how = 'left', on = [\"Health_Camp_ID\",\"Patient_ID\"])\n",
    "train.loc[train['Outcome'].isnull(), 'Outcome'] = 0   \n",
    "train['Outcome'] = train['Outcome'].astype(np.int32)\n",
    "\n",
    "# Separate Outcome data\n",
    "y_train = train['Outcome']\n",
    "X_train =  train.drop('Outcome', axis = 1)\n",
    "X_test = test\n",
    "\n",
    "train.columns\n",
    "\n",
    "train=train[['Patient_ID', 'Health_Camp_ID', 'Registration_Date', 'Var1', 'Var2',\n",
    "       'Var3', 'Var4', 'Var5', 'Outcome']]\n",
    "\n",
    "train\n",
    "\n",
    "\n",
    "test = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\test_l0Auv8Q.csv\", sep = \",\")\n",
    "health_camp  = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Health_Camp_Detail.csv', sep = \",\")\n",
    "patient = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Patient_Profile.csv', sep = \",\")\n",
    "first_format_camp = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\First_Health_Camp_Attended.csv', sep = \",\")\n",
    "second_format_camp = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Second_Health_Camp_Attended.csv', sep = \",\")\n",
    "third_format_camp = pd.read_csv(r'C:\\Users\\LENOVO\\Downloads\\Train_2\\Train\\Third_Health_Camp_Attended.csv', sep = \",\")\n",
    "\n",
    "import sys\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, model_selection, metrics, ensemble\n",
    "import xgboost as xgb\n",
    "\n",
    "def getCountVar(compute_df, count_df, var_name, count_var=\"v1\"):\n",
    "    grouped_df = count_df.groupby(var_name, as_index=False).agg('size').reset_index()\n",
    "    grouped_df.columns = [var_name, \"var_count\"]\n",
    "    merged_df = pd.merge(compute_df, grouped_df, how=\"left\", on=var_name)\n",
    "    merged_df.fillna(-1, inplace=True)\n",
    "    return list(merged_df[\"var_count\"])\n",
    "\n",
    "def create_feature_map(features):\n",
    "outfile = open('xgb.fmap', 'w')\n",
    "for i, feat in enumerate(features):\n",
    "outfile.write('{0}\\t{1}\\tq\\n'.format(i,feat))\n",
    "outfile.close()\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, extra_X=None, seed_val=0, num_rounds=200):\n",
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params['eval_metric'] = 'auc'\n",
    "params[\"eta\"] = 0.02 \n",
    "params[\"subsample\"] = 0.8\n",
    "params[\"min_child_weight\"] = 5\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"max_depth\"] = 6\n",
    "params[\"silent\"] = 1\n",
    "params[\"seed\"] = seed_val\n",
    "\n",
    "plst = list(params.items())\n",
    "xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "if test_y is not None:\n",
    "xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=300)\n",
    "else:\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "if feature_names is not None:\n",
    "create_feature_map(feature_names)\n",
    "model.dump_model('xgbmodel.txt', 'xgb.fmap', with_stats=True)\n",
    "importance = model.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "imp_df = pd.DataFrame(importance, columns=['feature','fscore'])\n",
    "imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()\n",
    "imp_df.to_csv(\"imp_feat.txt\", index=False)\n",
    "\n",
    "pred_test_y = model.predict(xgtest)\n",
    "loss = 0\n",
    "\n",
    "if extra_X is not None:\n",
    "xgtest = xgb.DMatrix(extra_X)\n",
    "pred_extra_y = model.predict(xgtest)\n",
    "return pred_test_y, pred_extra_y, loss \n",
    "\n",
    "if test_y is not None:\n",
    "loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "print (loss)\n",
    "return pred_test_y, loss\n",
    "else:\n",
    "    return pred_test_y,loss\n",
    "\n",
    "\n",
    "## Get only the necessary columns and rename them for concatenating ##\n",
    "col_names = [['Patient_ID','Health_Camp_ID','Outcome']]\n",
    "first_camp = first_format_camp[['Patient_ID','Health_Camp_ID','Health_Score']]\n",
    "first_camp.columns = col_names\n",
    "second_camp = second_format_camp[['Patient_ID','Health_Camp_ID','Health Score']]\n",
    "second_camp.columns = col_names\n",
    "third_camp = third_format_camp[['Patient_ID','Health_Camp_ID','Number_of_stall_visited']]\n",
    "third_camp = third_camp[third_camp['Number_of_stall_visited']>0]\n",
    "third_camp.columns = col_names\n",
    "\n",
    "test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "## Reading the files and converting the dates ##\n",
    "\n",
    "train['Registration_Date'].fillna('10-jan-90', inplace=True)\n",
    "test['Registration_Date'].fillna('10-jan-90', inplace=True)\n",
    "train['Registration_Date'] = pd.to_datetime(train['Registration_Date'], format=\"%d-%b-%y\")\n",
    "test['Registration_Date'] = pd.to_datetime(test['Registration_Date'], format=\"%d-%b-%y\")\n",
    "train['Registration_Date'] = train['Registration_Date'].apply(lambda x: x.toordinal())\n",
    "test['Registration_Date'] = test['Registration_Date'].apply(lambda x: x.toordinal())\n",
    "print (train.shape, test.shape)\n",
    "\n",
    "\n",
    "\n",
    "## Getting patient details and merging with train and test ##\n",
    "\n",
    "patient['First_Interaction'] = pd.to_datetime(patient['First_Interaction'], format=\"%d-%b-%y\")\n",
    "patient['First_Interaction'] = patient['First_Interaction'].apply(lambda x: x.toordinal())\n",
    "print (patient.shape)\n",
    "train = train.merge(patient, on=['Patient_ID'], how='left')\n",
    "test = test.merge(patient, on=['Patient_ID'], how='left')\n",
    "print (train.shape, test.shape)\n",
    "\n",
    "## Getting health camp details and merging with train and test ##\n",
    "hc_details = health_camp\n",
    "hc_ids = list(hc_details.Health_Camp_ID.values)\n",
    "hc_details['Camp_Start_Date'] = pd.to_datetime(hc_details['Camp_Start_Date'], format=\"%d-%b-%y\")\n",
    "hc_details['Camp_End_Date'] = pd.to_datetime(hc_details['Camp_End_Date'], format=\"%d-%b-%y\")\n",
    "hc_details['Camp_Start_Date'] = hc_details['Camp_Start_Date'].apply(lambda x: x.toordinal())\n",
    "hc_details['Camp_End_Date'] = hc_details['Camp_End_Date'].apply(lambda x: x.toordinal())\n",
    "hc_details['Camp_Duration_Days'] = hc_details['Camp_End_Date'] - hc_details['Camp_Start_Date']\n",
    "print (hc_details.head())\n",
    "train = train.merge(hc_details, on=['Health_Camp_ID'], how='left')\n",
    "test = test.merge(hc_details, on=['Health_Camp_ID'], how='left')\n",
    "print (train.shape, test.shape)\n",
    "\n",
    "## Reading the camp files ##\n",
    "first_camp_details = first_format_camp\n",
    "first_camp_details = first_camp_details[[\"Patient_ID\",\"Health_Camp_ID\",\"Donation\",\"Health_Score\"]]\n",
    "train = train.merge(first_camp_details, on=[\"Patient_ID\",\"Health_Camp_ID\"], how='left')\n",
    "third_camp_details = third_format_camp\n",
    "third_camp_details = third_camp_details[[\"Patient_ID\",\"Health_Camp_ID\",\"Number_of_stall_visited\",\"Last_Stall_Visited_Number\"]]\n",
    "train = train.merge(third_camp_details, on=[\"Patient_ID\",\"Health_Camp_ID\"], how='left')\n",
    "train[\"Number_of_stall_visited\"].fillna(0, inplace=True)\n",
    "train[\"Donation\"].fillna(0, inplace=True)\n",
    "train[\"Health_Score\"].fillna(0, inplace=True)\n",
    "print (train.shape, test.shape)\n",
    "\n",
    "\n",
    "## Filling NA with -99 ##\n",
    "train.fillna(-99, inplace=True)\n",
    "test.fillna(-99, inplace=True)\n",
    "\n",
    "## print create additional features ##\n",
    "print (\"Getting additional features.\")\n",
    "train[\"Diff_CampStart_Registration\"] = train[\"Camp_Start_Date\"] - train[\"Registration_Date\"]\n",
    "test[\"Diff_CampStart_Registration\"] = test[\"Camp_Start_Date\"] - test[\"Registration_Date\"]\n",
    "\n",
    "train[\"Diff_CampEnd_Registration\"] = train[\"Camp_End_Date\"] - train[\"Registration_Date\"]\n",
    "test[\"Diff_CampEnd_Registration\"] = test[\"Camp_End_Date\"] - test[\"Registration_Date\"]\n",
    "\n",
    "train[\"Diff_Registration_FirstInteraction\"] = train[\"Registration_Date\"] - train[\"First_Interaction\"]\n",
    "test[\"Diff_Registration_FirstInteraction\"] = test[\"Registration_Date\"] - test[\"First_Interaction\"]\n",
    "\n",
    "train[\"Diff_CampStart_FirstInteraction\"] = train[\"Camp_Start_Date\"] - train[\"First_Interaction\"]\n",
    "test[\"Diff_CampStart_FirstInteraction\"] = test[\"Camp_Start_Date\"] - test[\"First_Interaction\"]\n",
    "print (train.shape, test.shape)\n",
    "\n",
    "## Getitng the cat columns and label encode them ##\n",
    "cat_columns = []\n",
    "for col in train.columns:\n",
    "if train[col].dtype == 'object':\n",
    "print (col)\n",
    "cat_columns.append(col)\n",
    "enc = preprocessing.LabelEncoder()\n",
    "full_list = list(train[col].values) + list(test[col].values)\n",
    "enc.fit(full_list)\n",
    "train[col] = enc.transform(list(train[col].values))\n",
    "test[col]  = enc.transform(list(test[col].values))\n",
    "\n",
    "# getting count #\n",
    "for col in [\"Patient_ID\", \"Health_Camp_ID\"]:\n",
    "print (\"Count : \", col)\n",
    "full_df = pd.concat([train, test])\n",
    "train[\"Count_\"+col] = getCountVar(train, full_df, col)\n",
    "test[\"Count_\"+col] = getCountVar(test, full_df, col)\n",
    "\n",
    "\n",
    "## do sorting so as to compute the next variables ##\n",
    "train = train.sort_values(['Camp_Start_Date', 'Camp_End_Date', 'Patient_ID']).reset_index(drop=True)\n",
    "test = test.sort_values(['Camp_Start_Date', 'Camp_End_Date', 'Patient_ID']).reset_index(drop=True)\n",
    "print (train.head())\n",
    "\n",
    "print (\"First pass to get necessary details..\")\n",
    "people_camp_dict = {}\n",
    "people_date_dict = {}\n",
    "people_dv_dict = {}\n",
    "people_cat1_dict = {}\n",
    "people_cdate_dict = {}\n",
    "people_donation_dict = {}\n",
    "people_num_stall_dict = {}\n",
    "people_last_stall_dict = {}\n",
    "people_fscore_dict = {}\n",
    "for ind, row in train.iterrows():\n",
    "pid = row['Patient_ID']\n",
    "cid = row['Health_Camp_ID']\n",
    "reg_date = row['Registration_Date']\n",
    "dv = row['Outcome']\n",
    "cat1 = row['Category1']\n",
    "cdate = row['Camp_Start_Date']\n",
    "donation = row['Donation']\n",
    "num_stall = row['Number_of_stall_visited']\n",
    "fscore = row['Health_Score']\n",
    "\n",
    "tlist = people_camp_dict.get(pid,[])\n",
    "tlist.append(cid)\n",
    "people_camp_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_date_dict.get(pid,[])\n",
    "tlist.append(reg_date)\n",
    "people_date_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_dv_dict.get(pid, [])\n",
    "tlist.append(dv)\n",
    "people_dv_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_donation_dict.get(pid, [])\n",
    "tlist.append(donation)\n",
    "people_donation_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_num_stall_dict.get(pid, [])\n",
    "tlist.append(num_stall)\n",
    "people_num_stall_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_fscore_dict.get(pid, [])\n",
    "tlist.append(fscore)\n",
    "people_fscore_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_cat1_dict.get(pid, [])\n",
    "tlist.append(cat1)\n",
    "people_cat1_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_cdate_dict.get(pid, [])\n",
    "tlist.append(cdate)\n",
    "people_cdate_dict[pid] = tlist[:]\n",
    "\n",
    "print (\"Creating features now using dict for train..\")\n",
    "last_date_list = []\n",
    "last_dv_list = []\n",
    "last_cat1_list = []\n",
    "mean_dv_list = []\n",
    "last_cdate_list = []\n",
    "last_donation_list = []\n",
    "last_num_stall_list = []\n",
    "last_fscore_list=[]\n",
    "for ind, row in train.iterrows():\n",
    "pid = row['Patient_ID']\n",
    "reg_date = row['Registration_Date']\n",
    "cat1 = row['Category1']\n",
    "cid = row['Health_Camp_ID']\n",
    "cdate = row['Camp_Start_Date']\n",
    "\n",
    "camp_list = people_camp_dict[pid]\n",
    "for ind, camp in enumerate(camp_list):\n",
    "if camp == cid:\n",
    "use_index = ind\n",
    "break\n",
    "\n",
    "tlist = people_date_dict[pid][:use_index]\n",
    "if len(tlist)>0:\n",
    "last_date_list.append(reg_date-tlist[-1])\n",
    "else:\n",
    "last_date_list.append(-99)\n",
    "\n",
    "tlist = people_dv_dict[pid][:use_index]\n",
    "if len(tlist)>0:\n",
    "last_dv_list.append(tlist[-1])\n",
    "mean_dv_list.append(np.mean(tlist))\n",
    "else:\n",
    "last_dv_list.append(-99)\n",
    "mean_dv_list.append(-99)\n",
    "\n",
    "tlist = people_donation_dict[pid][:use_index]\n",
    "if len(tlist)>0:\n",
    "last_donation_list.append(np.sum(tlist))\n",
    "else:\n",
    "last_donation_list.append(-99)\n",
    "\n",
    "tlist = people_num_stall_dict[pid][:use_index]\n",
    "if len(tlist)>0:\n",
    "last_num_stall_list.append(np.sum(tlist))\n",
    "else:\n",
    "last_num_stall_list.append(-99)\n",
    "\n",
    "tlist = people_fscore_dict[pid][:use_index]\n",
    "if len(tlist)>0:\n",
    "last_fscore_list.append(np.mean([i for i in tlist if i!=0]))\n",
    "else:\n",
    "last_fscore_list.append(-99)\n",
    "\n",
    "tlist = people_cat1_dict[pid][:use_index]\n",
    "if len(tlist)>0:\n",
    "last_cat1_list.append(tlist[-1])\n",
    "else:\n",
    "last_cat1_list.append(-99)\n",
    "\n",
    "tlist = people_date_dict[pid][use_index+1:]\n",
    "if len(tlist)>0:\n",
    "last_cdate_list.append(reg_date-tlist[0]) \n",
    "else:\n",
    "last_cdate_list.append(-99)\n",
    "\n",
    "print (last_fscore_list[:50])\n",
    "\n",
    "train[\"Last_Reg_Date\"] = last_date_list[:]\n",
    "train[\"Mean_Outcome\"] = mean_dv_list[:]\n",
    "train[\"Last_Cat1\"] = last_cat1_list[:]\n",
    "train[\"Next_Reg_Date\"] = last_cdate_list\n",
    "train[\"Sum_Donations\"] = last_donation_list[:]\n",
    "train[\"Sum_NumStalls\"] = last_num_stall_list[:]\n",
    "train[\"Mean_Fscore\"] = last_fscore_list[:]\n",
    "\n",
    "print (\"Prepare dict using val..\")\n",
    "for ind, row in test.iterrows():\n",
    "pid = row['Patient_ID']\n",
    "cid = row['Health_Camp_ID']\n",
    "reg_date = row['Registration_Date']\n",
    "cat1 = row['Category1']\n",
    "cdate = row['Camp_Start_Date']\n",
    "\n",
    "tlist = people_camp_dict.get(pid,[])\n",
    "tlist.append(cid)\n",
    "people_camp_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_date_dict.get(pid,[])\n",
    "tlist.append(reg_date)\n",
    "people_date_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_cat1_dict.get(pid, [])\n",
    "tlist.append(cat1)\n",
    "people_cat1_dict[pid] = tlist[:]\n",
    "\n",
    "tlist = people_cdate_dict.get(pid, [])\n",
    "tlist.append(cdate)\n",
    "people_cdate_dict[pid] = tlist[:]\n",
    "\n",
    "print (\"Creating features for val using dict..\")\n",
    "last_date_list = []\n",
    "last_dv_list = []\n",
    "last_cat1_list = []\n",
    "mean_dv_list = []\n",
    "last_cdate_list = []\n",
    "last_donation_list = []\n",
    "last_num_stall_list = []\n",
    "last_fscore_list = []\n",
    "for ind, row in test.iterrows():\n",
    "pid = row['Patient_ID']\n",
    "reg_date = row['Registration_Date']\n",
    "cat1 = row['Category1']\n",
    "cid = row['Health_Camp_ID']\n",
    "cdate = row['Camp_Start_Date']\n",
    "\n",
    "camp_list = people_camp_dict[pid]\n",
    "for ind, camp in enumerate(camp_list):\n",
    "if camp == cid:\n",
    "use_index = ind\n",
    "break\n",
    "\n",
    "tlist = people_date_dict[pid][:use_index]\n",
    "if len(tlist)>0:\n",
    "last_date_list.append(reg_date-tlist[-1])\n",
    "else:\n",
    "last_date_list.append(-99)\n",
    "\n",
    "tlist = people_dv_dict.get(pid, [])\n",
    "if len(tlist)>0:\n",
    "last_dv_list.append(tlist[-1])\n",
    "mean_dv_list.append(np.mean(tlist))\n",
    "else:\n",
    "last_dv_list.append(-99)\n",
    "mean_dv_list.append(-99)\n",
    "\n",
    "tlist = people_donation_dict.get(pid, [])\n",
    "if len(tlist)>0:\n",
    "last_donation_list.append(np.sum(tlist))\n",
    "else:\n",
    "last_donation_list.append(-99)\n",
    "\n",
    "tlist = people_num_stall_dict.get(pid, [])\n",
    "if len(tlist)>0:\n",
    "last_num_stall_list.append(np.sum(tlist))\n",
    "else:\n",
    "last_num_stall_list.append(-99)\n",
    "\n",
    "tlist = people_fscore_dict.get(pid, [])\n",
    "if len(tlist)>0:\n",
    "last_fscore_list.append(np.mean([i for i in tlist if i!=0]))\n",
    "else:\n",
    "last_fscore_list.append(-99)\n",
    "\n",
    "tlist = people_cat1_dict[pid][:use_index]\n",
    "if len(tlist)>0:\n",
    "last_cat1_list.append(tlist[-1])\n",
    "else:\n",
    "last_cat1_list.append(-99)\n",
    "\n",
    "tlist = people_date_dict[pid][use_index+1:]\n",
    "if len(tlist)>0:\n",
    "last_cdate_list.append(reg_date-tlist[0])\n",
    "else:\n",
    "last_cdate_list.append(-99)\n",
    "\n",
    "test[\"Last_Reg_Date\"] = last_date_list[:]\n",
    "test[\"Mean_Outcome\"] = mean_dv_list[:]\n",
    "test[\"Last_Cat1\"] = last_cat1_list[:]\n",
    "test[\"Next_Reg_Date\"] = last_cdate_list[:]\n",
    "test[\"Sum_Donations\"] = last_donation_list[:]\n",
    "test[\"Sum_NumStalls\"] = last_num_stall_list[:]\n",
    "test[\"Mean_Fscore\"] = last_fscore_list[:]\n",
    "\n",
    "train.fillna(-99, inplace=True)\n",
    "test.fillna(-99, inplace=True)\n",
    "\n",
    "print (\"Getting dv and id values\")\n",
    "train_y = train.Outcome.values\n",
    "\n",
    "## Columns to drop ##\n",
    "print (\"Dropping columns..\")\n",
    "drop_cols = [\"Camp_Start_Date\", \"Camp_End_Date\", \"Registration_Date\"] #, \"First_Interaction\"]\n",
    "drop_cols = drop_cols + [\"LinkedIn_Shared\", \"Facebook_Shared\", \"Twitter_Shared\", \"Online_Follower\", \"Var4\"]\n",
    "train.drop(drop_cols, axis=1, inplace=True) \n",
    "test.drop(drop_cols, axis=1, inplace=True) \n",
    "print (train.shape, test.shape)\n",
    "\n",
    "# preparing train and test #\n",
    "print (\"Choose the columns to use..\")\n",
    "xcols = [col for col in train.columns if col not in [\"Outcome\", \"Health_Camp_ID\", \"Patient_ID\", \"Der_Var1\", \"Number_of_stall_visited\",\"Last_Stall_Visited_Number\", \"Donation\", \"Health_Score\", \"Mean_Fscore\"]]\n",
    "print (xcols)\n",
    "train_X = np.array(train[xcols])\n",
    "test_X = np.array(test[xcols])\n",
    "print (train_X.shape, test_X.shape)\n",
    "\n",
    "\n",
    "print( \"Final Model..\")\n",
    "preds = 0\n",
    "for seed_val, num_rounds in [[0,200], [2016,250], [1323, 225]]:\n",
    "print (seed_val, num_rounds)\n",
    "temp_preds, loss = runXGB(train_X, train_y, test_X, feature_names=xcols, seed_val=seed_val, num_rounds=num_rounds)\n",
    "preds += temp_preds\n",
    "preds = preds/3.\n",
    "\n",
    "out_df = pd.DataFrame({\"Patient_ID\":test.Patient_ID.values})\n",
    "out_df[\"Health_Camp_ID\"] = test.Health_Camp_ID.values\n",
    "out_df[\"Outcome\"] =  preds\n",
    "out_df.to_csv(\"s.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
